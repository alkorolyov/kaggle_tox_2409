{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T06:48:00.878556Z",
     "start_time": "2024-09-16T06:48:00.803075Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T06:48:45.888097Z",
     "start_time": "2024-09-16T06:48:45.799425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ],
   "id": "7924b967ce99ae5c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T06:48:56.672658Z",
     "start_time": "2024-09-16T06:48:54.827119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = pd.read_pickle('../data/processed/X_train.pkl.zip')\n",
    "y_train = pd.read_pickle('../data/processed/y_train.pkl')"
   ],
   "id": "af4da4024b43390",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T06:55:18.311132Z",
     "start_time": "2024-09-16T06:55:17.394544Z"
    }
   },
   "cell_type": "code",
   "source": "train_data = pd.concat([X_train, y_train], axis=1)",
   "id": "6c80a69c4242c8d0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T06:55:19.448552Z",
     "start_time": "2024-09-16T06:55:19.351530Z"
    }
   },
   "cell_type": "code",
   "source": "train_data.columns",
   "id": "7ae62640e0c19ae8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ecfp:4_0', 'ecfp:4_1', 'ecfp:4_2', 'ecfp:4_3', 'ecfp:4_4', 'ecfp:4_5',\n",
       "       'ecfp:4_6', 'ecfp:4_7', 'ecfp:4_8', 'ecfp:4_9',\n",
       "       ...\n",
       "       'gin_supervised_masking_294', 'gin_supervised_masking_295',\n",
       "       'gin_supervised_masking_296', 'gin_supervised_masking_297',\n",
       "       'gin_supervised_masking_298', 'gin_supervised_masking_299', 'prop_1',\n",
       "       'prop_2', 'prop_3', 'target'],\n",
       "      dtype='object', length=12835)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T06:57:34.650710900Z",
     "start_time": "2024-09-16T06:55:44.218231Z"
    }
   },
   "cell_type": "code",
   "source": "reg = TabularPredictor(label='target', eval_metric='roc_auc').fit(train_data)",
   "id": "e49db985dbfca651",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240916_065544\"\n",
      "C:\\Users\\alexander.korolyov\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7939 samples, 815.24 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240916_065544\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "Disk Space Avail:   90.16 GB / 511.33 GB (17.6%)\n",
      "Train Data Rows:    7939\n",
      "Train Data Columns: 12834\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "C:\\Users\\alexander.korolyov\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "C:\\Users\\alexander.korolyov\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10318.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 815.11 MB (7.9% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 7.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8265 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 377): ['topological_7', 'topological_11', 'topological_18', 'topological_19', 'topological_39', 'topological_47', 'topological_55', 'topological_59', 'topological_63', 'topological_71', 'topological_75', 'topological_82', 'topological_83', 'topological_87', 'topological_99', 'topological_103', 'topological_106', 'topological_107', 'topological_111', 'topological_115', 'topological_123', 'topological_127', 'topological_131', 'topological_135', 'topological_138', 'topological_139', 'topological_143', 'topological_147', 'topological_155', 'topological_163', 'topological_167', 'topological_171', 'topological_175', 'topological_183', 'topological_187', 'topological_195', 'topological_199', 'topological_203', 'topological_207', 'topological_215', 'topological_219', 'topological_223', 'topological_226', 'topological_227', 'topological_231', 'topological_243', 'topological_255', 'topological_258', 'topological_259', 'topological_263', 'topological_279', 'topological_291', 'topological_295', 'topological_299', 'topological_311', 'topological_319', 'topological_327', 'topological_335', 'topological_343', 'topological_355', 'topological_358', 'topological_359', 'topological_363', 'topological_367', 'topological_371', 'topological_395', 'topological_403', 'topological_407', 'topological_419', 'topological_443', 'topological_463', 'topological_475', 'topological_487', 'topological_491', 'topological_507', 'topological_519', 'topological_543', 'topological_555', 'topological_563', 'topological_567', 'topological_571', 'topological_603', 'topological_611', 'topological_619', 'topological_627', 'topological_631', 'topological_643', 'topological_647', 'topological_659', 'topological_671', 'topological_675', 'topological_679', 'topological_682', 'topological_683', 'topological_699', 'topological_703', 'topological_707', 'topological_711', 'topological_719', 'topological_723', 'topological_727', 'topological_743', 'topological_747', 'topological_755', 'topological_758', 'topological_759', 'topological_767', 'topological_771', 'topological_775', 'topological_782', 'topological_783', 'topological_787', 'topological_795', 'topological_799', 'topological_807', 'topological_811', 'topological_815', 'topological_823', 'topological_827', 'topological_835', 'topological_839', 'topological_843', 'topological_847', 'topological_863', 'topological_867', 'topological_875', 'topological_879', 'topological_883', 'topological_891', 'topological_894', 'topological_895', 'topological_899', 'topological_903', 'topological_911', 'topological_915', 'topological_919', 'topological_927', 'topological_935', 'topological_939', 'topological_951', 'topological_959', 'topological_963', 'topological_967', 'topological_970', 'topological_971', 'topological_975', 'topological_978', 'topological_979', 'topological_983', 'topological_995', 'topological_1011', 'topological_1019', 'topological_1023', 'layered_674', 'pattern_37', 'pattern_212', 'pattern_429', 'pattern_1022', 'erg_295', 'erg_296', 'erg_297', 'erg_298', 'erg_299', 'erg_300', 'erg_301', 'erg_302', 'erg_303', 'erg_304', 'erg_305', 'erg_306', 'erg_307', 'erg_308', 'erg_309', 'erg_310', 'erg_311', 'erg_312', 'erg_313', 'erg_314', 'maccs_0', 'maccs_1', 'maccs_2', 'maccs_3', 'maccs_4', 'maccs_5', 'maccs_6', 'maccs_7', 'maccs_9', 'maccs_10', 'maccs_12', 'maccs_18', 'maccs_20', 'maccs_35', 'maccs_44', 'maccs_166', 'estate_0', 'estate_1', 'estate_2', 'estate_3', 'estate_4', 'estate_5', 'estate_19', 'estate_21', 'estate_26', 'estate_38', 'estate_39', 'estate_40', 'estate_41', 'estate_42', 'estate_43', 'estate_54', 'estate_55', 'estate_56', 'estate_57', 'estate_58', 'estate_59', 'estate_60', 'estate_61', 'estate_62', 'estate_63', 'estate_64', 'estate_65', 'estate_66', 'estate_67', 'estate_68', 'estate_70', 'estate_71', 'estate_72', 'estate_73', 'estate_75', 'estate_76', 'estate_77', 'estate_78', 'desc2D_69', 'desc2D_82', 'desc2D_163', 'desc2D_197', 'desc2D_210', 'desc2D_211', 'mordred_24', 'mordred_871', 'mordred_891', 'mordred_892', 'mordred_893', 'mordred_894', 'mordred_895', 'mordred_896', 'mordred_910', 'mordred_912', 'mordred_917', 'mordred_929', 'mordred_930', 'mordred_931', 'mordred_932', 'mordred_933', 'mordred_934', 'mordred_945', 'mordred_946', 'mordred_947', 'mordred_948', 'mordred_949', 'mordred_950', 'mordred_951', 'mordred_952', 'mordred_953', 'mordred_954', 'mordred_955', 'mordred_956', 'mordred_957', 'mordred_958', 'mordred_959', 'mordred_961', 'mordred_962', 'mordred_963', 'mordred_964', 'mordred_966', 'mordred_967', 'mordred_968', 'mordred_969', 'mordred_970', 'mordred_971', 'mordred_972', 'mordred_973', 'mordred_974', 'mordred_975', 'mordred_989', 'mordred_991', 'mordred_996', 'mordred_1008', 'mordred_1009', 'mordred_1010', 'mordred_1011', 'mordred_1012', 'mordred_1013', 'mordred_1024', 'mordred_1025', 'mordred_1026', 'mordred_1027', 'mordred_1028', 'mordred_1029', 'mordred_1030', 'mordred_1031', 'mordred_1032', 'mordred_1033', 'mordred_1034', 'mordred_1035', 'mordred_1036', 'mordred_1037', 'mordred_1038', 'mordred_1040', 'mordred_1041', 'mordred_1042', 'mordred_1043', 'mordred_1045', 'mordred_1046', 'mordred_1047', 'mordred_1048', 'mordred_1095', 'mordred_1174', 'mordred_1327', 'mordred_1337', 'mordred_1438', 'mordred_1443', 'mordred_1444', 'mordred_1445', 'mordred_1446', 'mordred_1450', 'mordred_1455', 'mordred_1456', 'mordred_1457', 'mordred_1458', 'mordred_1487', 'mordred_1498', 'mordred_1508', 'mordred_1509', 'mordred_1510', 'mordred_1511', 'mordred_1519', 'mordred_1520', 'mordred_1521', 'mordred_1522', 'mordred_1531', 'mordred_1542', 'cats2D_36', 'cats2D_100', 'cats2D_108', 'cats2D_117', 'cats2D_118', 'cats2D_144', 'cats2D_171', 'cats3D_5', 'cats3D_11', 'cats3D_17', 'cats3D_23', 'cats3D_24', 'cats3D_29', 'cats3D_35', 'cats3D_41', 'cats3D_47', 'cats3D_53', 'cats3D_59', 'cats3D_65', 'cats3D_67', 'cats3D_71', 'cats3D_72', 'cats3D_77', 'cats3D_78', 'cats3D_79', 'cats3D_83', 'cats3D_89', 'cats3D_95', 'cats3D_96', 'cats3D_101', 'cats3D_107', 'cats3D_113', 'cats3D_114', 'cats3D_119', 'cats3D_125']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 421): ['topological_6', 'topological_22', 'topological_23', 'topological_27', 'topological_31', 'topological_35', 'topological_38', 'topological_43', 'topological_46', 'topological_54', 'topological_58', 'topological_67', 'topological_70', 'topological_79', 'topological_91', 'topological_102', 'topological_119', 'topological_122', 'topological_134', 'topological_142', 'topological_151', 'topological_162', 'topological_179', 'topological_190', 'topological_191', 'topological_198', 'topological_206', 'topological_211', 'topological_214', 'topological_235', 'topological_247', 'topological_271', 'topological_298', 'topological_303', 'topological_307', 'topological_318', 'topological_326', 'topological_339', 'topological_351', 'topological_362', 'topological_399', 'topological_415', 'topological_423', 'topological_427', 'topological_431', 'topological_435', 'topological_439', 'topological_447', 'topological_451', 'topological_471', 'topological_479', 'topological_483', 'topological_495', 'topological_515', 'topological_518', 'topological_535', 'topological_546', 'topological_547', 'topological_551', 'topological_562', 'topological_566', 'topological_575', 'topological_579', 'topological_583', 'topological_587', 'topological_591', 'topological_595', 'topological_599', 'topological_602', 'topological_606', 'topological_607', 'topological_623', 'topological_630', 'topological_698', 'topological_731', 'topological_754', 'topological_786', 'topological_798', 'topological_810', 'topological_831', 'topological_842', 'topological_851', 'topological_858', 'topological_859', 'topological_862', 'topological_866', 'topological_878', 'topological_882', 'topological_887', 'topological_890', 'topological_907', 'topological_926', 'topological_938', 'topological_943', 'topological_947', 'topological_955', 'topological_962', 'topological_982', 'topological_991', 'topological_1007', 'topological_1010', 'topological_1015', 'pattern_9', 'pattern_100', 'pattern_161', 'pattern_165', 'pattern_173', 'pattern_179', 'pattern_217', 'pattern_283', 'pattern_340', 'pattern_362', 'pattern_390', 'pattern_465', 'pattern_469', 'pattern_488', 'pattern_541', 'pattern_549', 'pattern_583', 'pattern_584', 'pattern_617', 'pattern_618', 'pattern_622', 'pattern_673', 'pattern_689', 'pattern_699', 'pattern_702', 'pattern_740', 'pattern_937', 'pattern_963', 'pattern_967', 'pattern_972', 'pattern_1003', 'erg_223', 'erg_237', 'maccs_60', 'maccs_143', 'maccs_163', 'estate_44', 'estate_46', 'estate_51', 'desc2D_1', 'desc2D_10', 'desc2D_42', 'desc2D_131', 'desc2D_142', 'desc2D_146', 'desc2D_147', 'desc2D_174', 'desc2D_175', 'desc2D_193', 'desc2D_199', 'desc2D_203', 'desc2D_206', 'desc2D_213', 'mordred_19', 'mordred_20', 'mordred_21', 'mordred_22', 'mordred_30', 'mordred_31', 'mordred_32', 'mordred_33', 'mordred_34', 'mordred_770', 'mordred_776', 'mordred_792', 'mordred_817', 'mordred_818', 'mordred_897', 'mordred_900', 'mordred_901', 'mordred_902', 'mordred_903', 'mordred_904', 'mordred_905', 'mordred_906', 'mordred_907', 'mordred_908', 'mordred_909', 'mordred_911', 'mordred_913', 'mordred_914', 'mordred_915', 'mordred_916', 'mordred_918', 'mordred_919', 'mordred_920', 'mordred_921', 'mordred_922', 'mordred_923', 'mordred_924', 'mordred_925', 'mordred_926', 'mordred_927', 'mordred_928', 'mordred_935', 'mordred_936', 'mordred_937', 'mordred_938', 'mordred_939', 'mordred_940', 'mordred_941', 'mordred_942', 'mordred_943', 'mordred_944', 'mordred_960', 'mordred_965', 'mordred_1137', 'mordred_1160', 'mordred_1172', 'mordred_1179', 'mordred_1255', 'mordred_1256', 'mordred_1306', 'mordred_1307', 'mordred_1308', 'mordred_1309', 'mordred_1310', 'mordred_1311', 'mordred_1312', 'mordred_1313', 'mordred_1314', 'mordred_1315', 'mordred_1316', 'mordred_1317', 'mordred_1318', 'mordred_1319', 'mordred_1320', 'mordred_1321', 'mordred_1322', 'mordred_1323', 'mordred_1324', 'mordred_1325', 'mordred_1326', 'mordred_1328', 'mordred_1329', 'mordred_1330', 'mordred_1331', 'mordred_1332', 'mordred_1333', 'mordred_1334', 'mordred_1335', 'mordred_1336', 'mordred_1338', 'mordred_1339', 'mordred_1340', 'mordred_1341', 'mordred_1342', 'mordred_1343', 'mordred_1344', 'mordred_1345', 'mordred_1346', 'mordred_1347', 'mordred_1348', 'mordred_1349', 'mordred_1350', 'mordred_1351', 'mordred_1352', 'mordred_1353', 'mordred_1354', 'mordred_1355', 'mordred_1356', 'mordred_1357', 'mordred_1358', 'mordred_1413', 'mordred_1415', 'mordred_1421', 'mordred_1422', 'mordred_1427', 'mordred_1432', 'mordred_1433', 'mordred_1434', 'mordred_1439', 'mordred_1447', 'mordred_1448', 'mordred_1451', 'mordred_1454', 'mordred_1459', 'mordred_1460', 'mordred_1462', 'mordred_1463', 'mordred_1467', 'mordred_1468', 'mordred_1469', 'mordred_1470', 'mordred_1471', 'mordred_1472', 'mordred_1474', 'mordred_1475', 'mordred_1478', 'mordred_1479', 'mordred_1480', 'mordred_1481', 'mordred_1482', 'mordred_1483', 'mordred_1484', 'mordred_1486', 'mordred_1497', 'mordred_1501', 'mordred_1505', 'mordred_1515', 'mordred_1523', 'mordred_1524', 'mordred_1526', 'mordred_1527', 'mordred_1530', 'mordred_1532', 'mordred_1533', 'mordred_1537', 'mordred_1541', 'mordred_1543', 'mordred_1544', 'mordred_1545', 'mordred_1548', 'mordred_1549', 'mordred_1551', 'mordred_1553', 'mordred_1554', 'mordred_1555', 'mordred_1584', 'cats2D_0', 'cats2D_27', 'cats2D_37', 'cats2D_45', 'cats2D_63', 'cats2D_90', 'cats2D_153', 'cats2D_180', 'scaffoldkeys_5', 'scaffoldkeys_7', 'scaffoldkeys_8', 'scaffoldkeys_9', 'scaffoldkeys_10', 'scaffoldkeys_12', 'scaffoldkeys_17', 'scaffoldkeys_27', 'skeys_0', 'skeys_1', 'skeys_2', 'skeys_3', 'skeys_4', 'skeys_5', 'skeys_6', 'skeys_7', 'skeys_8', 'skeys_9', 'skeys_10', 'skeys_11', 'skeys_12', 'skeys_13', 'skeys_14', 'skeys_15', 'skeys_16', 'skeys_17', 'skeys_18', 'skeys_19', 'skeys_20', 'skeys_21', 'skeys_22', 'skeys_23', 'skeys_24', 'skeys_25', 'skeys_26', 'skeys_27', 'skeys_28', 'skeys_29', 'skeys_30', 'skeys_31', 'skeys_32', 'skeys_33', 'skeys_34', 'skeys_35', 'skeys_36', 'skeys_37', 'skeys_38', 'skeys_39', 'skeys_40', 'skeys_41', 'cats3D_0', 'cats3D_1', 'cats3D_6', 'cats3D_12', 'cats3D_13', 'cats3D_18', 'cats3D_19', 'cats3D_25', 'cats3D_30', 'cats3D_31', 'cats3D_36', 'cats3D_42', 'cats3D_43', 'cats3D_48', 'cats3D_54', 'cats3D_60', 'cats3D_61', 'cats3D_66', 'cats3D_73', 'cats3D_84', 'cats3D_85', 'cats3D_90', 'cats3D_91', 'cats3D_97', 'cats3D_102', 'cats3D_103', 'cats3D_108', 'cats3D_109', 'cats3D_120', 'cats3D_121', 'usrcat_0', 'usrcat_1', 'usrcat_2', 'usrcat_3', 'usrcat_4', 'usrcat_5', 'usrcat_6', 'usrcat_7', 'usrcat_8', 'usrcat_9', 'usrcat_10', 'usrcat_11']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 421 | ['topological_6', 'topological_22', 'topological_23', 'topological_27', 'topological_31', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12036 | ['ecfp:4_0', 'ecfp:4_1', 'ecfp:4_2', 'ecfp:4_3', 'ecfp:4_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 3957 | ['erg_0', 'erg_1', 'erg_2', 'erg_3', 'erg_4', ...]\n",
      "\t\t('int', ['bool']) : 8079 | ['ecfp:4_0', 'ecfp:4_1', 'ecfp:4_2', 'ecfp:4_3', 'ecfp:4_4', ...]\n",
      "\t82.9s = Fit runtime\n",
      "\t12036 features in original data used to generate 12036 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 315.46 MB (2.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 85.7s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7145, Val Rows: 794\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 1.238 GB out of 9.732 GB available memory (63.623%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.69 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 1.238 GB out of 9.725 GB available memory (63.672%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.69 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: LightGBMXT ...\n",
      "C:\\Users\\alexander.korolyov\\miniforge3\\envs\\chem\\lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m reg \u001B[38;5;241m=\u001B[39m \u001B[43mTabularPredictor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtarget\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mroc_auc\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001B[0m, in \u001B[0;36munpack.<locals>._unpack_inner.<locals>._call\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     30\u001B[0m     gargs, gkwargs \u001B[38;5;241m=\u001B[39m g(\u001B[38;5;241m*\u001B[39mother_args, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39mgargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgkwargs)\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:986\u001B[0m, in \u001B[0;36mTabularPredictor.fit\u001B[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001B[0m\n\u001B[0;32m    984\u001B[0m     aux_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_weighted_ensemble\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    985\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave(silent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# Save predictor to disk to enable prediction and training after interrupt\u001B[39;00m\n\u001B[1;32m--> 986\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_learner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    987\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    988\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtuning_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    989\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munlabeled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    990\u001B[0m \u001B[43m    \u001B[49m\u001B[43mholdout_frac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mholdout_frac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    991\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_bag_folds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_bag_folds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    992\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_bag_sets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_bag_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    993\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_stack_levels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_stack_levels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    994\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    995\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcore_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcore_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    996\u001B[0m \u001B[43m    \u001B[49m\u001B[43maux_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maux_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    997\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    998\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_bag_holdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_bag_holdout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1002\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_post_fit_vars()\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_fit(\n\u001B[0;32m   1006\u001B[0m     keep_only_best\u001B[38;5;241m=\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeep_only_best\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1007\u001B[0m     refit_full\u001B[38;5;241m=\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrefit_full\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     infer_limit\u001B[38;5;241m=\u001B[39minfer_limit,\n\u001B[0;32m   1013\u001B[0m )\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001B[0m, in \u001B[0;36mAbstractTabularLearner.fit\u001B[1;34m(self, X, X_val, **kwargs)\u001B[0m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLearner is already fit.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_fit_input(X\u001B[38;5;241m=\u001B[39mX, X_val\u001B[38;5;241m=\u001B[39mX_val, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(X\u001B[38;5;241m=\u001B[39mX, X_val\u001B[38;5;241m=\u001B[39mX_val, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:157\u001B[0m, in \u001B[0;36mDefaultLearner._fit\u001B[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval_metric \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39meval_metric\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave()\n\u001B[1;32m--> 157\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m    158\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m    159\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m    160\u001B[0m     X_val\u001B[38;5;241m=\u001B[39mX_val,\n\u001B[0;32m    161\u001B[0m     y_val\u001B[38;5;241m=\u001B[39my_val,\n\u001B[0;32m    162\u001B[0m     X_unlabeled\u001B[38;5;241m=\u001B[39mX_unlabeled,\n\u001B[0;32m    163\u001B[0m     holdout_frac\u001B[38;5;241m=\u001B[39mholdout_frac,\n\u001B[0;32m    164\u001B[0m     time_limit\u001B[38;5;241m=\u001B[39mtime_limit_trainer,\n\u001B[0;32m    165\u001B[0m     infer_limit\u001B[38;5;241m=\u001B[39minfer_limit,\n\u001B[0;32m    166\u001B[0m     infer_limit_batch_size\u001B[38;5;241m=\u001B[39minfer_limit_batch_size,\n\u001B[0;32m    167\u001B[0m     groups\u001B[38;5;241m=\u001B[39mgroups,\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrainer_fit_kwargs,\n\u001B[0;32m    169\u001B[0m )\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_trainer(trainer\u001B[38;5;241m=\u001B[39mtrainer)\n\u001B[0;32m    171\u001B[0m time_end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:114\u001B[0m, in \u001B[0;36mAutoTrainer.fit\u001B[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m log_str \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    112\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m20\u001B[39m, log_str)\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_multi_and_ensemble\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_stack_levels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_stack_levels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcore_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcore_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43maux_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maux_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2419\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi_and_ensemble\u001B[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001B[0m\n\u001B[0;32m   2417\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_rows_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(X_val)\n\u001B[0;32m   2418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_cols_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mlist\u001B[39m(X\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[1;32m-> 2419\u001B[0m model_names_fit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_multi_levels(\n\u001B[0;32m   2420\u001B[0m     X,\n\u001B[0;32m   2421\u001B[0m     y,\n\u001B[0;32m   2422\u001B[0m     hyperparameters\u001B[38;5;241m=\u001B[39mhyperparameters,\n\u001B[0;32m   2423\u001B[0m     X_val\u001B[38;5;241m=\u001B[39mX_val,\n\u001B[0;32m   2424\u001B[0m     y_val\u001B[38;5;241m=\u001B[39my_val,\n\u001B[0;32m   2425\u001B[0m     X_unlabeled\u001B[38;5;241m=\u001B[39mX_unlabeled,\n\u001B[0;32m   2426\u001B[0m     level_start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   2427\u001B[0m     level_end\u001B[38;5;241m=\u001B[39mnum_stack_levels \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   2428\u001B[0m     time_limit\u001B[38;5;241m=\u001B[39mtime_limit,\n\u001B[0;32m   2429\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2430\u001B[0m )\n\u001B[0;32m   2431\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_names()) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   2432\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoGluon did not successfully train any models\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:383\u001B[0m, in \u001B[0;36mAbstractTrainer.train_multi_levels\u001B[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001B[0m\n\u001B[0;32m    381\u001B[0m         core_kwargs_level[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m core_kwargs_level\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m, time_limit_core)\n\u001B[0;32m    382\u001B[0m         aux_kwargs_level[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m aux_kwargs_level\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m, time_limit_aux)\n\u001B[1;32m--> 383\u001B[0m     base_model_names, aux_models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack_new_level\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    384\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_model_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_model_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcore_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcore_kwargs_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    393\u001B[0m \u001B[43m        \u001B[49m\u001B[43maux_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maux_kwargs_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname_suffix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname_suffix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43minfer_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    396\u001B[0m \u001B[43m        \u001B[49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    398\u001B[0m     model_names_fit \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m base_model_names \u001B[38;5;241m+\u001B[39m aux_models\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_best \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(model_names_fit) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:527\u001B[0m, in \u001B[0;36mAbstractTrainer.stack_new_level\u001B[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001B[0m\n\u001B[0;32m    525\u001B[0m     core_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m core_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m name_suffix\n\u001B[0;32m    526\u001B[0m     aux_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m aux_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m name_suffix\n\u001B[1;32m--> 527\u001B[0m core_models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstack_new_level_core(\n\u001B[0;32m    528\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m    529\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m    530\u001B[0m     X_val\u001B[38;5;241m=\u001B[39mX_val,\n\u001B[0;32m    531\u001B[0m     y_val\u001B[38;5;241m=\u001B[39my_val,\n\u001B[0;32m    532\u001B[0m     X_unlabeled\u001B[38;5;241m=\u001B[39mX_unlabeled,\n\u001B[0;32m    533\u001B[0m     models\u001B[38;5;241m=\u001B[39mmodels,\n\u001B[0;32m    534\u001B[0m     level\u001B[38;5;241m=\u001B[39mlevel,\n\u001B[0;32m    535\u001B[0m     infer_limit\u001B[38;5;241m=\u001B[39minfer_limit,\n\u001B[0;32m    536\u001B[0m     infer_limit_batch_size\u001B[38;5;241m=\u001B[39minfer_limit_batch_size,\n\u001B[0;32m    537\u001B[0m     base_model_names\u001B[38;5;241m=\u001B[39mbase_model_names,\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcore_kwargs,\n\u001B[0;32m    539\u001B[0m )\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X_val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    542\u001B[0m     aux_models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstack_new_level_aux(\n\u001B[0;32m    543\u001B[0m         X\u001B[38;5;241m=\u001B[39mX, y\u001B[38;5;241m=\u001B[39my, base_model_names\u001B[38;5;241m=\u001B[39mcore_models, level\u001B[38;5;241m=\u001B[39mlevel \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, infer_limit\u001B[38;5;241m=\u001B[39minfer_limit, infer_limit_batch_size\u001B[38;5;241m=\u001B[39minfer_limit_batch_size, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39maux_kwargs\n\u001B[0;32m    544\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:661\u001B[0m, in \u001B[0;36mAbstractTrainer.stack_new_level_core\u001B[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001B[0m\n\u001B[0;32m    658\u001B[0m fit_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes)\n\u001B[0;32m    660\u001B[0m \u001B[38;5;66;03m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001B[39;00m\n\u001B[1;32m--> 661\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_multi(\n\u001B[0;32m    662\u001B[0m     X\u001B[38;5;241m=\u001B[39mX_init,\n\u001B[0;32m    663\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m    664\u001B[0m     X_val\u001B[38;5;241m=\u001B[39mX_val,\n\u001B[0;32m    665\u001B[0m     y_val\u001B[38;5;241m=\u001B[39my_val,\n\u001B[0;32m    666\u001B[0m     X_unlabeled\u001B[38;5;241m=\u001B[39mX_unlabeled,\n\u001B[0;32m    667\u001B[0m     models\u001B[38;5;241m=\u001B[39mmodels,\n\u001B[0;32m    668\u001B[0m     level\u001B[38;5;241m=\u001B[39mlevel,\n\u001B[0;32m    669\u001B[0m     stack_name\u001B[38;5;241m=\u001B[39mstack_name,\n\u001B[0;32m    670\u001B[0m     compute_score\u001B[38;5;241m=\u001B[39mcompute_score,\n\u001B[0;32m    671\u001B[0m     fit_kwargs\u001B[38;5;241m=\u001B[39mfit_kwargs,\n\u001B[0;32m    672\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    673\u001B[0m )\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2369\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi\u001B[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001B[0m\n\u001B[0;32m   2367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_repeat_start \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   2368\u001B[0m     time_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m-> 2369\u001B[0m     model_names_trained \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_multi_initial(\n\u001B[0;32m   2370\u001B[0m         X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   2371\u001B[0m         y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m   2372\u001B[0m         models\u001B[38;5;241m=\u001B[39mmodels,\n\u001B[0;32m   2373\u001B[0m         k_fold\u001B[38;5;241m=\u001B[39mk_fold,\n\u001B[0;32m   2374\u001B[0m         n_repeats\u001B[38;5;241m=\u001B[39mn_repeats_initial,\n\u001B[0;32m   2375\u001B[0m         hyperparameter_tune_kwargs\u001B[38;5;241m=\u001B[39mhyperparameter_tune_kwargs,\n\u001B[0;32m   2376\u001B[0m         feature_prune_kwargs\u001B[38;5;241m=\u001B[39mfeature_prune_kwargs,\n\u001B[0;32m   2377\u001B[0m         time_limit\u001B[38;5;241m=\u001B[39mtime_limit,\n\u001B[0;32m   2378\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2379\u001B[0m     )\n\u001B[0;32m   2380\u001B[0m     n_repeat_start \u001B[38;5;241m=\u001B[39m n_repeats_initial\n\u001B[0;32m   2381\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time_limit \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2208\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi_initial\u001B[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m   2206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m bagged:\n\u001B[0;32m   2207\u001B[0m     time_ratio \u001B[38;5;241m=\u001B[39m hpo_time_ratio \u001B[38;5;28;01mif\u001B[39;00m hpo_enabled \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 2208\u001B[0m     models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_multi_fold(\n\u001B[0;32m   2209\u001B[0m         models\u001B[38;5;241m=\u001B[39mmodels,\n\u001B[0;32m   2210\u001B[0m         hyperparameter_tune_kwargs\u001B[38;5;241m=\u001B[39mhyperparameter_tune_kwargs,\n\u001B[0;32m   2211\u001B[0m         time_limit\u001B[38;5;241m=\u001B[39mtime_limit,\n\u001B[0;32m   2212\u001B[0m         time_split\u001B[38;5;241m=\u001B[39mtime_split,\n\u001B[0;32m   2213\u001B[0m         time_ratio\u001B[38;5;241m=\u001B[39mtime_ratio,\n\u001B[0;32m   2214\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_args,\n\u001B[0;32m   2215\u001B[0m     )\n\u001B[0;32m   2216\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2217\u001B[0m     time_ratio \u001B[38;5;241m=\u001B[39m hpo_time_ratio \u001B[38;5;28;01mif\u001B[39;00m hpo_enabled \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2326\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi_fold\u001B[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m   2324\u001B[0m         time_start_model \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   2325\u001B[0m         time_left \u001B[38;5;241m=\u001B[39m time_limit \u001B[38;5;241m-\u001B[39m (time_start_model \u001B[38;5;241m-\u001B[39m time_start)\n\u001B[1;32m-> 2326\u001B[0m model_name_trained_lst \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_single_full(\n\u001B[0;32m   2327\u001B[0m     X, y, model, time_limit\u001B[38;5;241m=\u001B[39mtime_left, hyperparameter_tune_kwargs\u001B[38;5;241m=\u001B[39mhyperparameter_tune_kwargs_model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m   2328\u001B[0m )\n\u001B[0;32m   2330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m   2331\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m model\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2099\u001B[0m, in \u001B[0;36mAbstractTrainer._train_single_full\u001B[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001B[0m\n\u001B[0;32m   2095\u001B[0m         bagged_model_fit_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bagged_model_fit_kwargs(\n\u001B[0;32m   2096\u001B[0m             k_fold\u001B[38;5;241m=\u001B[39mk_fold, k_fold_start\u001B[38;5;241m=\u001B[39mk_fold_start, k_fold_end\u001B[38;5;241m=\u001B[39mk_fold_end, n_repeats\u001B[38;5;241m=\u001B[39mn_repeats, n_repeat_start\u001B[38;5;241m=\u001B[39mn_repeat_start\n\u001B[0;32m   2097\u001B[0m         )\n\u001B[0;32m   2098\u001B[0m         model_fit_kwargs\u001B[38;5;241m.\u001B[39mupdate(bagged_model_fit_kwargs)\n\u001B[1;32m-> 2099\u001B[0m     model_names_trained \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_and_save(\n\u001B[0;32m   2100\u001B[0m         X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   2101\u001B[0m         y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m   2102\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   2103\u001B[0m         X_val\u001B[38;5;241m=\u001B[39mX_val,\n\u001B[0;32m   2104\u001B[0m         y_val\u001B[38;5;241m=\u001B[39my_val,\n\u001B[0;32m   2105\u001B[0m         X_unlabeled\u001B[38;5;241m=\u001B[39mX_unlabeled,\n\u001B[0;32m   2106\u001B[0m         stack_name\u001B[38;5;241m=\u001B[39mstack_name,\n\u001B[0;32m   2107\u001B[0m         level\u001B[38;5;241m=\u001B[39mlevel,\n\u001B[0;32m   2108\u001B[0m         compute_score\u001B[38;5;241m=\u001B[39mcompute_score,\n\u001B[0;32m   2109\u001B[0m         total_resources\u001B[38;5;241m=\u001B[39mtotal_resources,\n\u001B[0;32m   2110\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_fit_kwargs,\n\u001B[0;32m   2111\u001B[0m     )\n\u001B[0;32m   2112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave()\n\u001B[0;32m   2113\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_names_trained\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1761\u001B[0m, in \u001B[0;36mAbstractTrainer._train_and_save\u001B[1;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001B[0m\n\u001B[0;32m   1759\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_fit_kwargs)\n\u001B[0;32m   1760\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1761\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_single(X, y, model, X_val, y_val, total_resources\u001B[38;5;241m=\u001B[39mtotal_resources, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_fit_kwargs)\n\u001B[0;32m   1763\u001B[0m fit_end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   1764\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_evaluation:\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1712\u001B[0m, in \u001B[0;36mAbstractTrainer._train_single\u001B[1;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001B[0m\n\u001B[0;32m   1707\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_train_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, model: AbstractModel, X_val\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, y_val\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, total_resources\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_fit_kwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AbstractModel:\n\u001B[0;32m   1708\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1709\u001B[0m \u001B[38;5;124;03m    Trains model but does not add the trained model to this Trainer.\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;124;03m    Returns trained model object.\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1712\u001B[0m     model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(X\u001B[38;5;241m=\u001B[39mX, y\u001B[38;5;241m=\u001B[39my, X_val\u001B[38;5;241m=\u001B[39mX_val, y_val\u001B[38;5;241m=\u001B[39my_val, total_resources\u001B[38;5;241m=\u001B[39mtotal_resources, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_fit_kwargs)\n\u001B[0;32m   1713\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:838\u001B[0m, in \u001B[0;36mAbstractModel.fit\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    836\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate_fit_resources(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_fit_memory_usage(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 838\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    840\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py:194\u001B[0m, in \u001B[0;36mLGBModel._fit\u001B[1;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001B[0m\n\u001B[0;32m    192\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategorical_column in param dict is overridden.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 194\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m train_lgb_model(early_stopping_callback_kwargs\u001B[38;5;241m=\u001B[39mearly_stopping_callback_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrain_params)\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m LightGBMError:\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m train_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py:124\u001B[0m, in \u001B[0;36mtrain_lgb_model\u001B[1;34m(early_stopping_callback_kwargs, **train_params)\u001B[0m\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m booster\u001B[38;5;241m.\u001B[39mfit(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrain_params)\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lgb\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrain_params)\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\lightgbm\\engine.py:292\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cb \u001B[38;5;129;01min\u001B[39;00m callbacks_before_iter:\n\u001B[0;32m    285\u001B[0m     cb(callback\u001B[38;5;241m.\u001B[39mCallbackEnv(model\u001B[38;5;241m=\u001B[39mbooster,\n\u001B[0;32m    286\u001B[0m                             params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m    287\u001B[0m                             iteration\u001B[38;5;241m=\u001B[39mi,\n\u001B[0;32m    288\u001B[0m                             begin_iteration\u001B[38;5;241m=\u001B[39minit_iteration,\n\u001B[0;32m    289\u001B[0m                             end_iteration\u001B[38;5;241m=\u001B[39minit_iteration \u001B[38;5;241m+\u001B[39m num_boost_round,\n\u001B[0;32m    290\u001B[0m                             evaluation_result_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m--> 292\u001B[0m \u001B[43mbooster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    294\u001B[0m evaluation_result_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    295\u001B[0m \u001B[38;5;66;03m# check evaluation result.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\chem\\lib\\site-packages\\lightgbm\\basic.py:3021\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, train_set, fobj)\u001B[0m\n\u001B[0;32m   3019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_objective_to_none:\n\u001B[0;32m   3020\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LightGBMError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCannot update due to null objective function.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 3021\u001B[0m _safe_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLGBM_BoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3022\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3023\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_finished\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   3024\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__is_predicted_cur_iter \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__num_dataset)]\n\u001B[0;32m   3025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m is_finished\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "chem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
